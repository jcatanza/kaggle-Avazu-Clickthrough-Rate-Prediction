{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict results for test data\n",
    "ref: https://www.kaggle.com/c/avazu-ctr-prediction/discussion/12314Â¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 0:10:06.923714\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "======================================================\n",
    "Out-of-core classification of  Avazu data\n",
    "======================================================\n",
    "wc count for train.csv 40428968\n",
    "wc count for test.csv   4577465\n",
    "This file reads archived training results (model_file and preproc_file),\n",
    "    makes the predictions for the test data, and writes the submission file to disk.\n",
    "\"\"\"\n",
    "\n",
    "# Author: Elena Cuoco <elena.cuoco@gmail.com>\n",
    "\n",
    "import string\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import  DataFrame\n",
    "import gc\n",
    "\n",
    "# joblib library for efficient archiving\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# initialize time\n",
    "start = datetime.now()\n",
    "\n",
    "# Set file and folder paths\n",
    "test_file = 'test.csv'\n",
    "model_path = './'\n",
    "submission_path = './'\n",
    "submission_file = submission_path + 'submission.csv'\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Main\n",
    "###############################################################################\n",
    "\n",
    "# read test data into a dataframe\n",
    "data = pd.read_table(test_file, sep=',', chunksize=None,header='infer',converters={\"id\":str})\n",
    "\n",
    "# load archived model_file and preproc_file from training step\n",
    "model_file = model_path + 'model-avazu-sgd.pkl'\n",
    "cls = joblib.load(model_file)\n",
    "preproc_file = model_path + 'model-avazu-preproc.pkl'\n",
    "preproc = joblib.load(preproc_file)\n",
    "\n",
    "# prepare test data for prediction step\n",
    "def hash_features(data):\n",
    "    \n",
    "    # engineered features related to categorical data\n",
    "    add_engineered_categorical_features = False\n",
    "    if add_engineered_categorical_features:\n",
    "        data['app']=data['app_id'].values+data['app_domain'].values+data['app_category'].values\n",
    "        data['site']=data['site_id'].values+data['site_domain'].values+data['site_category'].values\n",
    "        data['device']= data['device_id'].values+data['device_ip'].values+data['device_model'].values+(data['device_type'].values.astype(str))+(data['device_conn_type'].values.astype(str))\n",
    "        data['type']=data['device_type'].values +data['device_conn_type'].values \n",
    "        data['iden']=data['app_id'].values +data['site_id'].values +data['device_id'].values\n",
    "        data['domain']=data['app_domain'].values +data['site_domain'].values \n",
    "        data['category']=data['app_category'].values+data['site_category'].values\n",
    "        data['sum']=data['C1'].values +data['C14'].values +data['C15'].values \\\n",
    "            +data['C16'].values+data['C17'].values\\\n",
    "            +data['C18'].values+data['C19'].values+data['C20'].values+data['C21'].values\n",
    "        data['pos']= data['banner_pos'].values.astype(str)+data['app_category'].values+data['site_category'].values \n",
    "     \n",
    "    # add engineered features related to datetime\n",
    "    add_engineered_datetime_features = True\n",
    "    if add_engineered_datetime_features:\n",
    "        data['hour']=data['hour'].map(lambda x: datetime.strptime(str(x),\"%y%m%d%H\"))\n",
    "        data['dayoftheweek']=data['hour'].map(lambda x:  x.weekday())\n",
    "        data['day']=data['hour'].map(lambda x:  x.day)\n",
    "        data['hour']=data['hour'].map(lambda x:  x.hour)    \n",
    "    \n",
    "    #remove id column    \n",
    "    data = data.drop(['id'], axis=1)\n",
    "     \n",
    "    # Convert all features to str    \n",
    "    features = np.asarray(data.astype(str))\n",
    "\n",
    "    # hash all the features\n",
    "    features = preproc.transform(features)\n",
    "   \n",
    "    return features\n",
    "\n",
    "##############################################################################\n",
    "# predict results for test data, and build Kaggle's submission file ##########\n",
    "##############################################################################\n",
    "\n",
    "# convert 'id' to int\n",
    "data['id'] = data['id'].apply(lambda x: int(x))\n",
    "\n",
    "# hashed features for test data\n",
    "features = hash_features(data)\n",
    "\n",
    "\n",
    "\n",
    "# Get probability for positive class\n",
    "click_prob = cls.predict_proba(features)[:,1]\n",
    "\n",
    "# identifiers for test data examples\n",
    "id = data['id'].values\n",
    "\n",
    "# clean up\n",
    "del data\n",
    "gc.collect()\n",
    "\n",
    "# put results in a data frame\n",
    "df = pd.DataFrame({'id':id, 'click':click_prob})\n",
    "\n",
    "# Convert to str format\n",
    "df['id']= df['id'].astype(str)\n",
    "df['click'] = df['click'].astype(str)\n",
    "\n",
    "# write results to submission file directly from dataframe\n",
    "with open(submission_file, 'w') as outfile:\n",
    "    df.to_csv(outfile,header=True,index_label=None,index=False,encoding='utf-8')\n",
    "\n",
    "# Get elapsed time\n",
    "print('elapsed time: %s' % str(datetime.now() - start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit result to kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Click-Through Rate Prediction\n"
     ]
    }
   ],
   "source": [
    "# Submit to kaggle\n",
    "!kaggle competitions submit -c avazu-ctr-prediction -f submission.csv -m 'lightgbm_10_million_samples'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check submission score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileName        date                 description                    status    publicScore  privateScore  \n",
      "--------------  -------------------  -----------------------------  --------  -----------  ------------  \n",
      "submission.csv  2018-07-22 11:05:35  'lightgbm_10_million_samples'  complete  0.4025103    0.4008019     \n",
      "submission.csv  2018-07-22 06:55:20  'lightgbm_1_million_samples'   complete  0.4025103    0.4008019     \n",
      "submission.csv  2018-07-21 18:55:12  'lightgbm_1_million_samples'   complete  0.3998276    0.3978254     \n",
      "submission.csv  2018-07-21 18:16:50  'cuoco'                        complete  0.3998276    0.3978254     \n",
      "submission.csv  2018-07-21 17:18:30  'cuoco'                        complete  0.4087478    0.4070267     \n",
      "submission.csv  2018-07-21 04:03:37  'cuoco'                        complete  0.4069034    0.4051218     \n",
      "submission.csv  2018-07-21 02:15:44  'cuoco'                        complete  0.4069034    0.4051218     \n",
      "submission.csv  2018-07-21 02:10:12  'cuoco'                        complete  0.4069034    0.4051218     \n",
      "submission.csv  2018-07-20 23:57:05  'cuoco'                        complete  0.4069918    0.4049906     \n",
      "submission.csv  2018-07-20 20:08:26  'cuoco'                        complete  0.4240041    0.4218415     \n",
      "submission.csv  2018-07-18 04:22:44  'cuoco'                        complete  0.4040516    0.4020787     \n",
      "submission.csv  2018-07-18 02:29:05  'cuoco'                        complete  0.4027605    0.4009369     \n",
      "submission.csv  2018-07-17 21:31:37  cuoco kernel                   complete  0.4047208    0.4029359     \n",
      "submission.csv  2018-07-17 21:20:52  cuoco kernel                   complete  0.4027606    0.4009366     \n",
      "submission.csv  2018-07-17 21:08:54  cuoco kernel                   complete  0.4027613    0.4009373     \n",
      "submission.csv  2018-07-17 20:53:15  cuoco kernel                   complete  0.4027614    0.4009374     \n",
      "submission.csv  2018-07-17 20:16:31  cuoco kernel                   complete  0.4050852    0.4033466     \n",
      "submission.csv  2018-07-17 20:02:46  cuoco kernel                   complete  0.4064057    0.4045539     \n",
      "submission.csv  2018-07-17 19:53:36  cuoco kernel                   complete  0.4027613    0.4009374     \n",
      "submission.csv  2018-07-17 19:38:40  cuoco kernel                   complete  0.4047208    0.4029359     \n"
     ]
    }
   ],
   "source": [
    "# Check submission score\n",
    "!kaggle competitions submissions -c avazu-ctr-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Elena Cuoco <elena.cuoco@gmail.com>\n",
    "\n",
    "import string\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import  DataFrame\n",
    "import gc\n",
    "\n",
    "# joblib library for efficient archiving\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# initialize time\n",
    "start = datetime.now()\n",
    "\n",
    "# Set file and folder paths\n",
    "test_file = 'test.csv'\n",
    "model_path = './'\n",
    "submission_path = './'\n",
    "submission_file = submission_path + 'submission.csv'\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Main\n",
    "###############################################################################\n",
    "\n",
    "# read test data into a dataframe\n",
    "data = pd.read_table(test_file, sep=',', chunksize=None,header='infer',converters={\"id\":str})\n",
    "\n",
    "# load archived model_file and preproc_file from training step\n",
    "model_file = model_path + 'model-avazu-sgd.pkl'\n",
    "cls = joblib.load(model_file)\n",
    "preproc_file = model_path + 'model-avazu-preproc.pkl'\n",
    "preproc = joblib.load(preproc_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot metrics recorded during training...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "plot_metric() got multiple values for argument 'booster'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f10dceaefab6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Plot metrics recorded during training...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevals_result_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'logloss'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbooster_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: plot_metric() got multiple values for argument 'booster'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('Plot metrics recorded during training...')\n",
    "ax = lgb.plot_metric(cls.evals_result_, metric='logloss',booster=cls.booster_)\n",
    "plt.show()\n",
    "\n",
    "print('Plot feature importances...')\n",
    "ax = lgb.plot_importance(cls.feature_importances_, max_num_features=10)\n",
    "plt.show()\n",
    "\n",
    "print('Plot 84th tree...')  # one tree use categorical feature to split\n",
    "ax = lgb.plot_tree(cls, tree_index=83, figsize=(20, 8), show_info=['split_gain'])\n",
    "plt.show()\n",
    "\n",
    "print('Plot 84th tree with graphviz...')\n",
    "graph = cls.create_tree_digraph(cls, tree_index=83, name='Tree84')\n",
    "graph.render(view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_Booster__attr',\n",
       " '_Booster__boost',\n",
       " '_Booster__get_eval_info',\n",
       " '_Booster__higher_better_inner_eval',\n",
       " '_Booster__init_predictor',\n",
       " '_Booster__inner_eval',\n",
       " '_Booster__inner_predict',\n",
       " '_Booster__inner_predict_buffer',\n",
       " '_Booster__is_predicted_cur_iter',\n",
       " '_Booster__name_inner_eval',\n",
       " '_Booster__need_reload_eval_info',\n",
       " '_Booster__num_class',\n",
       " '_Booster__num_dataset',\n",
       " '_Booster__num_inner_eval',\n",
       " '_Booster__set_objective_to_none',\n",
       " '_Booster__train_data_name',\n",
       " '__class__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__del__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_free_buffer',\n",
       " '_load_model_from_string',\n",
       " '_save_model_to_string',\n",
       " '_to_predictor',\n",
       " 'add_valid',\n",
       " 'attr',\n",
       " 'best_iteration',\n",
       " 'best_score',\n",
       " 'current_iteration',\n",
       " 'dump_model',\n",
       " 'eval',\n",
       " 'eval_train',\n",
       " 'eval_valid',\n",
       " 'feature_importance',\n",
       " 'feature_name',\n",
       " 'free_dataset',\n",
       " 'free_network',\n",
       " 'get_leaf_output',\n",
       " 'handle',\n",
       " 'name_valid_sets',\n",
       " 'network',\n",
       " 'num_feature',\n",
       " 'pandas_categorical',\n",
       " 'predict',\n",
       " 'reset_parameter',\n",
       " 'rollback_one_iter',\n",
       " 'save_model',\n",
       " 'set_attr',\n",
       " 'set_network',\n",
       " 'set_train_data_name',\n",
       " 'update']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(cls.booster_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot metrics recorded during training...\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "You must install matplotlib to plot metric.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-5e679b9fdd5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Plot metrics recorded during training...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevals_result_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'logloss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\xgboost\\lib\\site-packages\\lightgbm\\plotting.py\u001b[0m in \u001b[0;36mplot_metric\u001b[1;34m(booster, metric, dataset_names, ax, xlim, ylim, title, xlabel, ylabel, figsize, grid)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'You must install matplotlib to plot metric.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLGBMModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: You must install matplotlib to plot metric."
     ]
    }
   ],
   "source": [
    "print('Plot metrics recorded during training...')\n",
    "ax = lgb.plot_metric(cls.evals_result_, metric='logloss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
