{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kaggle Avazu project \n",
    "https://www.kaggle.com/c/avazu-ctr-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-01 14:26:41.640387\tencountered: 100000\tcurrent logloss: 0.410952\n",
      "2018-07-01 14:26:56.397231\tencountered: 200000\tcurrent logloss: 0.406744\n",
      "2018-07-01 14:27:11.366087\tencountered: 300000\tcurrent logloss: 0.398390\n",
      "2018-07-01 14:27:33.189335\tencountered: 400000\tcurrent logloss: 0.389028\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c1edea4af3c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[1;31m# get predictions and train on all labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m         \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlogloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# for progressive validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-c1edea4af3c7>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(x, w)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[0mwTx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# do wTx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mwTx\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1.\u001b[0m  \u001b[1;31m# w[i] * x[i], but if i in x we got x[i] = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwTx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m20.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# bounded sigmoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %load fast_solution.py\n",
    "'''\n",
    "           DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE\n",
    "                   Version 2, December 2004\n",
    "\n",
    "Copyright (C) 2004 Sam Hocevar <sam@hocevar.net>\n",
    "Modified by : Abhishek Thakur <abhishek4@gmail.com>\n",
    "\n",
    "Everyone is permitted to copy and distribute verbatim or modified\n",
    "copies of this license document, and changing it is allowed as long\n",
    "as the name is changed.\n",
    "\n",
    "           DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE\n",
    "  TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION\n",
    "\n",
    " 0. You just DO WHAT THE FUCK YOU WANT TO.\n",
    "'''\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from math import log, exp, sqrt\n",
    "\n",
    "\n",
    "# TL; DR\n",
    "# the main learning process start at line 122\n",
    "\n",
    "\n",
    "# parameters #################################################################\n",
    "\n",
    "train = 'train.csv'  # path to training file\n",
    "test = 'test.csv'  # path to testing file\n",
    "\n",
    "D = 2 ** 20  # number of weights use for each model, we have 32 of them\n",
    "alpha = .1   # learning rate for sgd optimization\n",
    "\n",
    "\n",
    "# function, generator definitions ############################################\n",
    "\n",
    "# A. x, y generator\n",
    "# INPUT:\n",
    "#     path: path to train.csv or test.csv\n",
    "#     label_path: (optional) path to trainLabels.csv\n",
    "# YIELDS:\n",
    "#     ID: id of the instance (can also acts as instance count)\n",
    "#     x: a list of indices that its value is 1\n",
    "#     y: (if label_path is present) label value of y1 to y33\n",
    "def data(path, traindata=False):\n",
    "    for t, line in enumerate(open(path)):\n",
    "        # initialize our generator\n",
    "        if t == 0:\n",
    "            # create a static x,\n",
    "            # so we don't have to construct a new x for every instance\n",
    "            x = [0] * 27\n",
    "            # is the continue statement necessary?\n",
    "            continue\n",
    "        # parse x\n",
    "        for m, feat in enumerate(line.rstrip().split(',')):\n",
    "            if m == 0:\n",
    "                ID = int(feat)\n",
    "            elif traindata and m == 1:\n",
    "                y = [float(feat)]\n",
    "            else:\n",
    "                # one-hot encode everything with hash trick\n",
    "                # categorical: one-hotted\n",
    "                # boolean: ONE-HOTTED\n",
    "                # numerical: ONE-HOTTED!\n",
    "                # note, the build in hash(), although fast is not stable,\n",
    "                #       i.e., same value won't always have the same hash\n",
    "                #       on different machines\n",
    "                if traindata:\n",
    "                    x[m] = abs(hash(str(m) + '_' + feat)) % D\n",
    "                else:\n",
    "                    x[m+1] = abs(hash(str(m+1) + '_' + feat)) % D\n",
    "        # Why include x[0] and x[1]? Seems like we should ignore the first 2 entries of x, because they are both 0.\n",
    "        # And why does x have 27 entries?\n",
    "        yield (ID, x, y) if traindata else (ID, x)\n",
    "\n",
    "# B. Bounded logloss\n",
    "# INPUT:\n",
    "#     p: our prediction\n",
    "#     y: real answer\n",
    "# OUTPUT\n",
    "#     bounded logarithmic loss of p given y\n",
    "def logloss(p, y):\n",
    "    p = max(min(p, 1. - 10e-15), 10e-15)\n",
    "    return -log(p) if y == 1. else -log(1. - p)\n",
    "\n",
    "\n",
    "# C. Get probability estimation on x\n",
    "# INPUT:\n",
    "#     x: features\n",
    "#     w: weights\n",
    "# OUTPUT:\n",
    "#     probability of p(y = 1 | x; w)\n",
    "def predict(x, w):\n",
    "    wTx = 0.\n",
    "    for i in x:  # do wTx\n",
    "        wTx += w[i] * 1.  # w[i] * x[i], but if i in x we got x[i] = 1.\n",
    "    return 1. / (1. + exp(-max(min(wTx, 20.), -20.)))  # bounded sigmoid\n",
    "\n",
    "\n",
    "# D. Update given model\n",
    "# INPUT:\n",
    "# alpha: learning rate\n",
    "#     w: weights\n",
    "#     n: sum of previous absolute gradients for a given feature\n",
    "#        this is used for adaptive learning rate\n",
    "#     x: feature, a list of indices\n",
    "#     p: prediction of our model\n",
    "#     y: answer\n",
    "# MODIFIES:\n",
    "#     w: weights\n",
    "#     n: sum of past absolute gradients\n",
    "def update(alpha, w, n, x, p, y):\n",
    "    for i in x:\n",
    "        # alpha / sqrt(n) is the adaptive learning rate\n",
    "        # (p - y) * x[i] is the current gradient\n",
    "        # note that in our case, if i in x then x[i] = 1.\n",
    "        n[i] += abs(p - y)\n",
    "        w[i] -= (p - y) * 1. * alpha / sqrt(n[i])\n",
    "\n",
    "\n",
    "# training and testing #######################################################\n",
    "start = datetime.now()\n",
    "\n",
    "K = [0]\n",
    "\n",
    "w = [[0.] * D]\n",
    "n = [[0.] * D]\n",
    "\n",
    "loss = 0.\n",
    "\n",
    "tt = 1\n",
    "for ID, x, y in data(train, traindata = True):\n",
    "\n",
    "    # get predictions and train on all labels\n",
    "    for k in K:\n",
    "        p = predict(x, w[k])\n",
    "        update(alpha, w[k], n[k], x, p, y[k])\n",
    "        loss += logloss(p, y[k])  # for progressive validation\n",
    "\n",
    "    # print out progress, so that we know everything is working\n",
    "    if tt % 100000 == 0:\n",
    "        print('%s\\tencountered: %d\\tcurrent logloss: %f' % (\n",
    "                datetime.now(), tt, (loss * 1./tt)))\n",
    "    tt += 1\n",
    "\n",
    "with open('submission.csv', 'w') as outfile:\n",
    "    outfile.write('id,click\\n')\n",
    "    for ID, x in data(test):\n",
    "        for k in K:\n",
    "            p = predict(x, w[k])\n",
    "            outfile.write('%s,%s\\n' % (ID, str(p)))\n",
    "\n",
    "print('Done, elapsed time: %s' % str(datetime.now() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
